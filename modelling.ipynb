{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a36b5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Anomaly detection models\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Preprocessing and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# For handling extreme imbalance\n",
    "# Estimates class weight for the minority class, so that the model can learn well from minority class.\n",
    "from sklearn.utils.class_weight import compute_class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "254a5671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fire data: 8,140 records\n",
      "Weather data: 7,665 records\n",
      "\n",
      "Seasonal Distribution:\n",
      "  Autumn: 7,312 (89.8%)\n",
      "  Summer: 437 (5.4%)\n",
      "  Spring: 344 (4.2%)\n",
      "  Winter: 47 (0.6%)\n",
      "\n",
      "Winter fires (Jun-Aug): 47 total\n",
      "\n",
      "FRP Statistics:\n",
      "  Mean FRP: 33.69\n",
      "  75th percentile: 32.80\n",
      "  90th percentile: 79.54\n",
      "  95th percentile: 122.10\n",
      "Current Anomaly Definition Results:\n",
      "Threshold: FRP > 32.80 in winter months\n",
      "Anomalous fires: 10\n",
      "Percentage: 0.123%\n",
      "EXTREMELY LOW OUTLIERS - Need better definition!\n",
      "Testing Alternative Definitions:\n",
      "Top 10% FRP in winter: 5 samples\n",
      "Top 20% FRP in low season: 80 samples\n",
      "Top 5% FRP anywhere: 407 samples\n"
     ]
    }
   ],
   "source": [
    "# Load data and explore the class imbalance\n",
    "\n",
    "# Loading fire and weather data from parquet files.\n",
    "fire_data = pd.read_parquet('final_fire_df.parquet')\n",
    "weather_data = pd.read_parquet('daily_weather.parquet')\n",
    "\n",
    "print(f\"Fire data: {fire_data.shape[0]:,} records\")\n",
    "print(f\"Weather data: {weather_data.shape[0]:,} records\")\n",
    "\n",
    "# Exploring the extreme imbalance issue\n",
    "# Checks the current seasonal distribution of fires.\n",
    "seasonal_dist = fire_data['season'].value_counts()\n",
    "print(f\"\\nSeasonal Distribution:\")\n",
    "for season, count in seasonal_dist.items():\n",
    "    pct = count/len(fire_data)*100\n",
    "    print(f\"  {season}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "# Check monthly distribution of fires for winter months\n",
    "winter_fires = fire_data[fire_data['acq_date'].dt.month.isin([6, 7, 8])]\n",
    "print(f\"\\nWinter fires (Jun-Aug): {len(winter_fires):,} total\")\n",
    "\n",
    "# Check FRP distribution\n",
    "print(f\"\\nFRP Statistics:\")\n",
    "print(f\"  Mean FRP: {fire_data['frp'].mean():.2f}\")\n",
    "print(f\"  75th percentile: {fire_data['frp'].quantile(0.75):.2f}\")\n",
    "print(f\"  90th percentile: {fire_data['frp'].quantile(0.90):.2f}\")\n",
    "print(f\"  95th percentile: {fire_data['frp'].quantile(0.95):.2f}\")\n",
    "\n",
    "# Our Current definition of unusual fire is 'Top 25% FRP in winter'\n",
    "current_threshold = fire_data['frp'].quantile(0.75)\n",
    "current_outliers = fire_data[\n",
    "    (fire_data['frp'] > current_threshold) & \n",
    "    (fire_data['acq_date'].dt.month.isin([6, 7, 8]))\n",
    "]\n",
    "\n",
    "print(f\"Current Anomaly Definition Results:\")\n",
    "print(f\"Threshold: FRP > {current_threshold:.2f} in winter months\")\n",
    "print(f\"Anomalous fires: {len(current_outliers)}\")\n",
    "print(f\"Percentage: {len(current_outliers)/len(fire_data)*100:.3f}%\")\n",
    "\n",
    "if len(current_outliers) <= 15:\n",
    "    print(f\"EXTREMELY LOW OUTLIERS - Need better definition!\")\n",
    "    \n",
    "    # Trying alternative definitions\n",
    "    print(f\"Testing Alternative Definitions:\")\n",
    "    \n",
    "    # Alternative 1: Top 10% FRP in winter\n",
    "    alt1_threshold = fire_data['frp'].quantile(0.90)\n",
    "    alt1_outliers = fire_data[\n",
    "        (fire_data['frp'] > alt1_threshold) & \n",
    "        (fire_data['acq_date'].dt.month.isin([6, 7, 8]))\n",
    "    ]\n",
    "    print(f\"Top 10% FRP in winter: {len(alt1_outliers)} samples\")\n",
    "    \n",
    "    # Alternative 2: High FRP in low fire season (May-Aug)\n",
    "    alt2_threshold = fire_data['frp'].quantile(0.80)\n",
    "    alt2_outliers = fire_data[\n",
    "        (fire_data['frp'] > alt2_threshold) & \n",
    "        (fire_data['acq_date'].dt.month.isin([5, 6, 7, 8]))\n",
    "    ]\n",
    "    print(f\"Top 20% FRP in low season: {len(alt2_outliers)} samples\")\n",
    "    \n",
    "    # Alternative 3: Very high FRP anywhere (top 5%)\n",
    "    alt3_threshold = fire_data['frp'].quantile(0.95)\n",
    "    alt3_outliers = fire_data[fire_data['frp'] > alt3_threshold]\n",
    "    print(f\"Top 5% FRP anywhere: {len(alt3_outliers)} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ac0c57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with 8,140 fire samples\n",
      "Anomaly Definition Options:\n",
      "Option 1 - Top 5% FRP anywhere: 407 anomalies\n",
      "Option 2 - Top 10% FRP in low season: 35 anomalies\n",
      "Option 3 - Top 15% FRP in winter: 6 anomalies\n",
      "Final Anomaly Definition: Top 10% FRP in low season (threshold: 79.54)\n",
      "Dataset Summary:\n",
      "Total samples: 8,140\n",
      "Anomalous fires: 35 (0.43%)\n",
      "Normal fires: 8105 (99.57%)\n"
     ]
    }
   ],
   "source": [
    "def create_anomaly_dataset(anomaly_definition='flexible'):\n",
    "    \"\"\"\n",
    "    Creates a dataset for anomaly detection with our flexible anomaly definition\n",
    "    \"\"\"\n",
    "    \n",
    "    # Taking a manageable sample for faster training time.\n",
    "    # I initially planned to take a sample of 3000, but decided to use all the data\n",
    "    # since I found lesser anomalies.\n",
    "    fire_sample = fire_data.sample(n=len(fire_data), random_state=42)\n",
    "    print(f\"Working with {len(fire_sample):,} fire samples\")\n",
    "    \n",
    "    # Creating the combined dataset\n",
    "    combined_data = []\n",
    "    \n",
    "    for idx, fire in fire_sample.iterrows():\n",
    "        fire_date = fire['acq_date'].date()\n",
    "        fire_lat, fire_lon = fire['latitude'], fire['longitude']\n",
    "        \n",
    "        # Finding weather data for same date\n",
    "        weather_day = weather_data[weather_data['date'].dt.date == fire_date]\n",
    "        \n",
    "        if not weather_day.empty:\n",
    "            # Getting the nearest weather station using euclidean distance.\n",
    "            weather_day = weather_day.copy()\n",
    "            weather_day['distance'] = ((weather_day['latitude'] - fire_lat)**2 + \n",
    "                                     (weather_day['longitude'] - fire_lon)**2)**0.5\n",
    "            closest_weather = weather_day.loc[weather_day['distance'].idxmin()]\n",
    "            \n",
    "            # Creates feature record\n",
    "            record = {\n",
    "                # Fire characteristics\n",
    "                'frp': fire['frp'],\n",
    "                'brightness': fire['brightness'],\n",
    "                'confidence': 1 if fire['confidence'] == 'h' else 0,\n",
    "                'month': fire['acq_date'].month,\n",
    "                \n",
    "                # Weather features\n",
    "                'temp_max': closest_weather['temperature_2m_max'],\n",
    "                'temp_min': closest_weather['temperature_2m_min'],\n",
    "                'humidity_min': closest_weather['relative_humidity_2m_min'],\n",
    "                'humidity_max': closest_weather['relative_humidity_2m_max'],\n",
    "                'wind_speed': closest_weather['wind_speed_10m_max'],\n",
    "                'precipitation': closest_weather['precipitation_sum'],\n",
    "                'solar_radiation': closest_weather['shortwave_radiation_sum'],\n",
    "                \n",
    "                # Feature Engineering\n",
    "                'temp_range': closest_weather['temperature_2m_max'] - closest_weather['temperature_2m_min'],\n",
    "                'humidity_range': closest_weather['relative_humidity_2m_max'] - closest_weather['relative_humidity_2m_min'],\n",
    "                \n",
    "                # Date of the fire\n",
    "                'date': fire_date\n",
    "            }\n",
    "            combined_data.append(record)\n",
    "    \n",
    "    dataset = pd.DataFrame(combined_data)\n",
    "    \n",
    "    # Defining anomalies based on the chosen definition\n",
    "    if anomaly_definition == 'flexible':\n",
    "        # Choose definition that gives us 30-100 anomalies for better modeling\n",
    "        \n",
    "        # Test different thresholds\n",
    "        frp_95 = dataset['frp'].quantile(0.95)\n",
    "        frp_90 = dataset['frp'].quantile(0.90)\n",
    "        frp_85 = dataset['frp'].quantile(0.85)\n",
    "        \n",
    "        # Alternative 1: Top 5% FRP anywhere\n",
    "        opt1_anomalies = (dataset['frp'] > frp_95).sum()\n",
    "        \n",
    "        # Alternative 2: Top 10% FRP in low season (May-Aug)\n",
    "        opt2_anomalies = ((dataset['frp'] > frp_90) & \n",
    "                         (dataset['month'].isin([5, 6, 7, 8]))).sum()\n",
    "        \n",
    "        # Alternative 3: Top 15% FRP in winter (Jun-Aug)\n",
    "        opt3_anomalies = ((dataset['frp'] > frp_85) & \n",
    "                         (dataset['month'].isin([6, 7, 8]))).sum()\n",
    "        \n",
    "        print(f\"Anomaly Definition Options:\")\n",
    "        print(f\"Option 1 - Top 5% FRP anywhere: {opt1_anomalies} anomalies\")\n",
    "        print(f\"Option 2 - Top 10% FRP in low season: {opt2_anomalies} anomalies\")\n",
    "        print(f\"Option 3 - Top 15% FRP in winter: {opt3_anomalies} anomalies\")\n",
    "        \n",
    "        # Choose the option that gives us 30-100 anomalies\n",
    "        if 30 <= opt1_anomalies <= 100:\n",
    "            dataset['is_anomaly'] = (dataset['frp'] > frp_95).astype(int)\n",
    "            chosen_def = f\"Top 5% FRP anywhere (threshold: {frp_95:.2f})\"\n",
    "        elif 30 <= opt2_anomalies <= 100:\n",
    "            dataset['is_anomaly'] = ((dataset['frp'] > frp_90) & \n",
    "                                   (dataset['month'].isin([5, 6, 7, 8]))).astype(int)\n",
    "            chosen_def = f\"Top 10% FRP in low season (threshold: {frp_90:.2f})\"\n",
    "        elif 30 <= opt3_anomalies <= 100:\n",
    "            dataset['is_anomaly'] = ((dataset['frp'] > frp_85) & \n",
    "                                   (dataset['month'].isin([6, 7, 8]))).astype(int)\n",
    "            chosen_def = f\"Top 15% FRP in winter (threshold: {frp_85:.2f})\"\n",
    "        else:\n",
    "            # Code to choose the option with most anomalies.\n",
    "            if opt1_anomalies >= opt2_anomalies and opt1_anomalies >= opt3_anomalies:\n",
    "                dataset['is_anomaly'] = (dataset['frp'] > frp_95).astype(int)\n",
    "                chosen_def = f\"Top 5% FRP anywhere (threshold: {frp_95:.2f})\"\n",
    "            elif opt2_anomalies >= opt3_anomalies:\n",
    "                dataset['is_anomaly'] = ((dataset['frp'] > frp_90) & \n",
    "                                       (dataset['month'].isin([5, 6, 7, 8]))).astype(int)\n",
    "                chosen_def = f\"Top 10% FRP in low season (threshold: {frp_90:.2f})\"\n",
    "            else:\n",
    "                dataset['is_anomaly'] = ((dataset['frp'] > frp_85) & \n",
    "                                       (dataset['month'].isin([6, 7, 8]))).astype(int)\n",
    "                chosen_def = f\"Top 15% FRP in winter (threshold: {frp_85:.2f})\"\n",
    "    \n",
    "    anomaly_count = dataset['is_anomaly'].sum()\n",
    "    anomaly_pct = anomaly_count / len(dataset) * 100\n",
    "    \n",
    "    print(f\"Final Anomaly Definition: {chosen_def}\")\n",
    "    print(f\"Dataset Summary:\")\n",
    "    print(f\"Total samples: {len(dataset):,}\")\n",
    "    print(f\"Anomalous fires: {anomaly_count} ({anomaly_pct:.2f}%)\")\n",
    "    print(f\"Normal fires: {len(dataset) - anomaly_count} ({100-anomaly_pct:.2f}%)\")\n",
    "    \n",
    "    return dataset, chosen_def\n",
    "\n",
    "# Create the dataset\n",
    "dataset, anomaly_definition = create_anomaly_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69df9712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['frp', 'brightness', 'confidence', 'month', 'temp_max', 'temp_min', 'humidity_min', 'humidity_max', 'wind_speed', 'precipitation', 'solar_radiation', 'temp_range', 'humidity_range']\n",
      "Dataset shape: (8140, 13)\n",
      "Anomaly distribution: {0: 8105, 1: 35}\n",
      "Training set: 6512 samples (28 anomalies)\n",
      "Test set: 1628 samples (7 anomalies)\n",
      "Class weights for extreme imbalance: {0: 0.5021591610117212, 1: 116.28571428571429}\n"
     ]
    }
   ],
   "source": [
    "# Data preparation for anomaly detection\n",
    "def prepare_anomaly_data(data):\n",
    "    \"\"\"\n",
    "    Prepares data for both supervised and unsupervised anomaly detection\n",
    "    \"\"\"\n",
    "    \n",
    "    # Select features for modeling\n",
    "    feature_columns = [\n",
    "        'frp', 'brightness', 'confidence', 'month',\n",
    "        'temp_max', 'temp_min', 'humidity_min', 'humidity_max',\n",
    "        'wind_speed', 'precipitation', 'solar_radiation',\n",
    "        'temp_range', 'humidity_range'\n",
    "    ]\n",
    "    \n",
    "    X = data[feature_columns].copy()\n",
    "    y = data['is_anomaly'].copy()\n",
    "    \n",
    "    # Filling missing values with mean of the column.\n",
    "    X = X.fillna(X.mean())\n",
    "    \n",
    "    print(f\"Features: {feature_columns}\")\n",
    "    print(f\"Dataset shape: {X.shape}\")\n",
    "    print(f\"Anomaly distribution: {y.value_counts().to_dict()}\")\n",
    "    \n",
    "    # (80/20) Data split.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Scales features for anomaly detection\n",
    "    # StandardScaler scales features to have mean 0 and std 1.\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Converts scaled data back to DataFrames for easier handling.\n",
    "    X_train_scaled = pd.DataFrame(X_train_scaled, columns=feature_columns)\n",
    "    X_test_scaled = pd.DataFrame(X_test_scaled, columns=feature_columns)\n",
    "    \n",
    "    print(f\"Training set: {X_train_scaled.shape[0]} samples ({y_train.sum()} anomalies)\")\n",
    "    print(f\"Test set: {X_test_scaled.shape[0]} samples ({y_test.sum()} anomalies)\")\n",
    "    \n",
    "    # Calculates class weights for extreme imbalance\n",
    "    # This is used to heavily penalize wrong predictions for minority class.\n",
    "    if y_train.sum() > 0:  # Only if we have anomalies\n",
    "        # classes are the unique values in y_train.\n",
    "        # compute_class_weight is used to calculate class weights for extreme imbalance.\n",
    "        # 'balanced' is used to calculate class weights based on the class distribution.\n",
    "        classes = np.unique(y_train)\n",
    "        class_weights = compute_class_weight('balanced', classes=classes, y=y_train)\n",
    "        class_weight_dict = dict(zip(classes, class_weights))\n",
    "        print(f\"Class weights for extreme imbalance: {class_weight_dict}\")\n",
    "    else:\n",
    "        class_weight_dict = None\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test, feature_columns, scaler, class_weight_dict\n",
    "\n",
    "# Prepare the data\n",
    "X_train, X_test, y_train, y_test, features, scaler, class_weights = prepare_anomaly_data(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19752de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "UNSUPERVISED ANOMALY DETECTION: \n",
      "Training Isolation Forest: \n",
      "Isolation Forest trained\n",
      "Detected 20 anomalies in test set\n",
      "Training One-Class SVM: \n",
      "One-Class SVM trained\n",
      "Detected 38 anomalies in test set\n",
      "Training Local Outlier Factor: \n",
      "Local Outlier Factor trained\n",
      "Detected 19 anomalies in test set\n",
      "\n",
      "SUPERVISED MODELS WITH EXTREME CLASS BALANCING: \n",
      "Training Random Forest (Class Balanced): \n",
      "Random Forest trained\n",
      "Predicted 7 anomalies in test set\n",
      "Training Logistic Regression (Class Balanced): \n",
      "Logistic Regression trained\n",
      "Predicted 74 anomalies in test set\n",
      "\n",
      "All applicable models trained successfully!\n"
     ]
    }
   ],
   "source": [
    "# Train anomaly detection models\n",
    "def train_anomaly_models():\n",
    "    \"\"\"\n",
    "    Train both supervised and unsupervised anomaly detection models\n",
    "    \"\"\"\n",
    "    \n",
    "    models = {}\n",
    "    results = {}\n",
    "    \n",
    "    # UNSUPERVISED MODELS (Best for extreme imbalance)\n",
    "    print(\"\\nUNSUPERVISED ANOMALY DETECTION: \")\n",
    "    \n",
    "    # 1. Isolation Forest (My first choice)\n",
    "    print(\"Training Isolation Forest: \")\n",
    "    contamination = y_train.mean()  # Expected fraction of anomalies\n",
    "    isolation_forest = IsolationForest(\n",
    "        contamination=max(0.01, contamination),  # At least 1%\n",
    "        random_state=42,\n",
    "        n_estimators=100,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Fit on training data (unsupervised)\n",
    "    isolation_forest.fit(X_train)\n",
    "    \n",
    "    # Make predictions (-1 for anomaly, 1 for normal)\n",
    "    if_train_pred = isolation_forest.predict(X_train)\n",
    "    if_test_pred = isolation_forest.predict(X_test)\n",
    "    \n",
    "    # Convert to binary (0 for normal, 1 for anomaly)\n",
    "    if_train_binary = (if_train_pred == -1).astype(int)\n",
    "    if_test_binary = (if_test_pred == -1).astype(int)\n",
    "    \n",
    "    models['Isolation Forest'] = isolation_forest\n",
    "    results['Isolation Forest'] = {\n",
    "        'test_predictions': if_test_binary,\n",
    "        'train_predictions': if_train_binary,\n",
    "        'type': 'unsupervised'\n",
    "    }\n",
    "    \n",
    "    print(f\"Isolation Forest trained\")\n",
    "    print(f\"Detected {if_test_binary.sum()} anomalies in test set\")\n",
    "    \n",
    "    # 2. One-Class SVM\n",
    "    print(\"Training One-Class SVM: \")\n",
    "    one_class_svm = OneClassSVM(\n",
    "        nu=max(0.01, contamination),  # Expected fraction of outliers\n",
    "        kernel='rbf',\n",
    "        gamma='scale'\n",
    "    )\n",
    "    \n",
    "    one_class_svm.fit(X_train)\n",
    "    \n",
    "    oc_train_pred = one_class_svm.predict(X_train)\n",
    "    oc_test_pred = one_class_svm.predict(X_test)\n",
    "    \n",
    "    oc_train_binary = (oc_train_pred == -1).astype(int)\n",
    "    oc_test_binary = (oc_test_pred == -1).astype(int)\n",
    "    \n",
    "    models['One-Class SVM'] = one_class_svm\n",
    "    results['One-Class SVM'] = {\n",
    "        'test_predictions': oc_test_binary,\n",
    "        'train_predictions': oc_train_binary,\n",
    "        'type': 'unsupervised'\n",
    "    }\n",
    "    \n",
    "    print(f\"One-Class SVM trained\")\n",
    "    print(f\"Detected {oc_test_binary.sum()} anomalies in test set\")\n",
    "    \n",
    "    # 3. Local Outlier Factor (for novelty detection)\n",
    "    print(\"Training Local Outlier Factor: \")\n",
    "    lof = LocalOutlierFactor(\n",
    "        contamination=max(0.01, contamination),\n",
    "        novelty=True  # For predicting on new data\n",
    "    )\n",
    "    \n",
    "    lof.fit(X_train)\n",
    "    \n",
    "    lof_train_pred = lof.predict(X_train)\n",
    "    lof_test_pred = lof.predict(X_test)\n",
    "    \n",
    "    lof_train_binary = (lof_train_pred == -1).astype(int)\n",
    "    lof_test_binary = (lof_test_pred == -1).astype(int)\n",
    "    \n",
    "    models['Local Outlier Factor'] = lof\n",
    "    results['Local Outlier Factor'] = {\n",
    "        'test_predictions': lof_test_binary,\n",
    "        'train_predictions': lof_train_binary,\n",
    "        'type': 'unsupervised'\n",
    "    }\n",
    "    \n",
    "    print(f\"Local Outlier Factor trained\")\n",
    "    print(f\"Detected {lof_test_binary.sum()} anomalies in test set\")\n",
    "    \n",
    "    # SUPERVISED MODELS (Only if we have atleast 5 anomalies, then we can use Random Forest and\n",
    "    # Logistic Regression models that we had tried earlier.)\n",
    "    if y_train.sum() >= 5:  # Only if we have at least 5 anomalies\n",
    "        print(\"\\nSUPERVISED MODELS WITH EXTREME CLASS BALANCING: \")\n",
    "        \n",
    "        # 4. Random Forest with extreme class balancing (due to the low outlier count)\n",
    "        print(\"Training Random Forest (Class Balanced): \")\n",
    "        rf_model = RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=10,\n",
    "            class_weight='balanced_subsample',  # To handle extreme imbalance\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        rf_model.fit(X_train, y_train)\n",
    "        \n",
    "        rf_train_pred = rf_model.predict(X_train)\n",
    "        rf_test_pred = rf_model.predict(X_test)\n",
    "        \n",
    "        models['Random Forest'] = rf_model\n",
    "        results['Random Forest'] = {\n",
    "            'test_predictions': rf_test_pred,\n",
    "            'train_predictions': rf_train_pred,\n",
    "            'feature_importance': rf_model.feature_importances_,\n",
    "            'type': 'supervised'\n",
    "        }\n",
    "        \n",
    "        print(f\"Random Forest trained\")\n",
    "        print(f\"Predicted {rf_test_pred.sum()} anomalies in test set\")\n",
    "        \n",
    "        # 5. Logistic Regression with extreme class balancing\n",
    "        print(\"Training Logistic Regression (Class Balanced): \")\n",
    "        lr_model = LogisticRegression(\n",
    "            class_weight='balanced',\n",
    "            random_state=42,\n",
    "            max_iter=1000,\n",
    "            C=0.1  # Stronger regularization for small dataset, follows rules very strictly to prevent overfitting.\n",
    "        )\n",
    "        \n",
    "        lr_model.fit(X_train, y_train)\n",
    "        \n",
    "        lr_train_pred = lr_model.predict(X_train)\n",
    "        lr_test_pred = lr_model.predict(X_test)\n",
    "        \n",
    "        models['Logistic Regression'] = lr_model\n",
    "        results['Logistic Regression'] = {\n",
    "            'test_predictions': lr_test_pred,\n",
    "            'train_predictions': lr_train_pred,\n",
    "            'type': 'supervised'\n",
    "        }\n",
    "        \n",
    "        print(f\"Logistic Regression trained\")\n",
    "        print(f\"Predicted {lr_test_pred.sum()} anomalies in test set\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Skipping supervised models since there are too few anomalies for reliable training\")\n",
    "        print(\"Recommendedse unsupervised methods only\")\n",
    "    \n",
    "    print(\"\\nAll applicable models trained successfully!\")\n",
    "    return models, results\n",
    "\n",
    "# Train all models\n",
    "models, model_results = train_anomaly_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda59528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MODEL COMPARISON\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Detected</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Isolation Forest</td>\n",
       "      <td>unsupervised</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One-Class SVM</td>\n",
       "      <td>unsupervised</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.044</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Local Outlier Factor</td>\n",
       "      <td>unsupervised</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>supervised</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.857</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>supervised</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.148</td>\n",
       "      <td>74</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model          Type Precision Recall F1-Score  Detected  \\\n",
       "0      Isolation Forest  unsupervised     0.000  0.000    0.000        20   \n",
       "1         One-Class SVM  unsupervised     0.026  0.143    0.044        38   \n",
       "2  Local Outlier Factor  unsupervised     0.000  0.000    0.000        19   \n",
       "3         Random Forest    supervised     0.857  0.857    0.857         7   \n",
       "4   Logistic Regression    supervised     0.081  0.857    0.148        74   \n",
       "\n",
       "   Actual  \n",
       "0       7  \n",
       "1       7  \n",
       "2       7  \n",
       "3       7  \n",
       "4       7  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ISOLATION FOREST DETAILED RESULTS: \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      1621\n",
      "           1       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.98      1628\n",
      "   macro avg       0.50      0.49      0.50      1628\n",
      "weighted avg       0.99      0.98      0.99      1628\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "              Predicted\n",
      "              Normal  Anomaly\n",
      "Actual Normal   1601      20\n",
      "       Anomaly     7       0\n",
      "\n",
      "ONE-CLASS SVM DETAILED RESULTS: \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      1621\n",
      "           1       0.03      0.14      0.04         7\n",
      "\n",
      "    accuracy                           0.97      1628\n",
      "   macro avg       0.51      0.56      0.52      1628\n",
      "weighted avg       0.99      0.97      0.98      1628\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "              Predicted\n",
      "              Normal  Anomaly\n",
      "Actual Normal   1584      37\n",
      "       Anomaly     6       1\n",
      "\n",
      "LOCAL OUTLIER FACTOR DETAILED RESULTS: \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      1621\n",
      "           1       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.98      1628\n",
      "   macro avg       0.50      0.49      0.50      1628\n",
      "weighted avg       0.99      0.98      0.99      1628\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "              Predicted\n",
      "              Normal  Anomaly\n",
      "Actual Normal   1602      19\n",
      "       Anomaly     7       0\n",
      "\n",
      "RANDOM FOREST DETAILED RESULTS: \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1621\n",
      "           1       0.86      0.86      0.86         7\n",
      "\n",
      "    accuracy                           1.00      1628\n",
      "   macro avg       0.93      0.93      0.93      1628\n",
      "weighted avg       1.00      1.00      1.00      1628\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "              Predicted\n",
      "              Normal  Anomaly\n",
      "Actual Normal   1620       1\n",
      "       Anomaly     1       6\n",
      "\n",
      "LOGISTIC REGRESSION DETAILED RESULTS: \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      1621\n",
      "           1       0.08      0.86      0.15         7\n",
      "\n",
      "    accuracy                           0.96      1628\n",
      "   macro avg       0.54      0.91      0.56      1628\n",
      "weighted avg       1.00      0.96      0.97      1628\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "              Predicted\n",
      "              Normal  Anomaly\n",
      "Actual Normal   1553      68\n",
      "       Anomaly     1       6\n"
     ]
    }
   ],
   "source": [
    "# Evaluate anomaly detection models\n",
    "from IPython.display import display\n",
    "def evaluate_anomaly_models():\n",
    "    \"\"\"\n",
    "    Evaluates and compares all the anomaly detection models\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculates metrics for models with ground truth class labels. (y_test)\n",
    "    evaluation_results = {}\n",
    "    \n",
    "    for model_name, results in model_results.items():\n",
    "        test_preds = results['test_predictions']\n",
    "        \n",
    "        # Calculate metrics\n",
    "        if len(np.unique(y_test)) > 1 and len(np.unique(test_preds)) > 1:\n",
    "            # Only calculate when both classes exist\n",
    "            precision = precision_score(y_test, test_preds, zero_division=0)\n",
    "            recall = recall_score(y_test, test_preds, zero_division=0)\n",
    "            f1 = f1_score(y_test, test_preds, zero_division=0)\n",
    "            accuracy = accuracy_score(y_test, test_preds)\n",
    "        else:\n",
    "            precision = recall = f1 = accuracy = 0.0\n",
    "        \n",
    "        evaluation_results[model_name] = {\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'accuracy': accuracy,\n",
    "            'detected_anomalies': test_preds.sum(),\n",
    "            'actual_anomalies': y_test.sum()\n",
    "        }\n",
    "    \n",
    "    # Creates a comparison table\n",
    "    print(\"\\nMODEL COMPARISON\")\n",
    "    comparison_data = []\n",
    "    for model_name, metrics in evaluation_results.items():\n",
    "        comparison_data.append({\n",
    "            'Model': model_name,\n",
    "            'Type': model_results[model_name]['type'],\n",
    "            'Precision': f\"{metrics['precision']:.3f}\",\n",
    "            'Recall': f\"{metrics['recall']:.3f}\",\n",
    "            'F1-Score': f\"{metrics['f1_score']:.3f}\",\n",
    "            'Detected': metrics['detected_anomalies'],\n",
    "            'Actual': metrics['actual_anomalies']\n",
    "        })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    display(comparison_df)\n",
    "    \n",
    "    # Prints detailed results for each model\n",
    "    for model_name, results in model_results.items():\n",
    "        print(f\"\\n{model_name.upper()} DETAILED RESULTS: \")\n",
    "        test_preds = results['test_predictions']\n",
    "        \n",
    "        print(\"Classification Report:\")\n",
    "        if len(np.unique(y_test)) > 1 and len(np.unique(test_preds)) > 1:\n",
    "            report = classification_report(y_test, test_preds, zero_division=0)\n",
    "            print(report)\n",
    "            \n",
    "            # Confusion matrix\n",
    "            cm = confusion_matrix(y_test, test_preds)\n",
    "            print(f\"\\nConfusion Matrix:\")\n",
    "            print(f\"              Predicted\")\n",
    "            print(f\"              Normal  Anomaly\")\n",
    "            print(f\"Actual Normal   {cm[0,0] if cm.shape[0] > 0 else 0:4d}    {cm[0,1] if cm.shape[0] > 1 else 0:4d}\")\n",
    "            if cm.shape[0] > 1:\n",
    "                print(f\"       Anomaly  {cm[1,0]:4d}    {cm[1,1]:4d}\")\n",
    "        else:\n",
    "            print(\"Cannot generate classification report since there is insufficient class diversity\")\n",
    "    \n",
    "    return evaluation_results\n",
    "\n",
    "# Run evaluation\n",
    "evaluation_results = evaluate_anomaly_models()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
